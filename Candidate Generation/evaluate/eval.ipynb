{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 数据清洗\n",
    "\n",
    "清洗输出，有以下几种类型：\n",
    "\n",
    "1. 一些明显不合理的输出，如 'Material in cell culture: scaffold', 'Material in cell culture: not mentioned'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "\n",
    "schema = {\n",
    "    \"Seeded cell density\": [],\n",
    "    \"Number of cells\": [],\n",
    "    \"Material in cell culture\": [],\n",
    "    \"Concentration of material\": [],\n",
    "    \"Chip material\": [],\n",
    "    \"Cross-linking agent\": [],\n",
    "    \"Pore size\": [],\n",
    "    \"Diameter\": [],\n",
    "    \"Manufacturing method\": [],\n",
    "    \"Perfusion rate\": [],\n",
    "    \"Channel width\": [],\n",
    "    \"Channel height\": []\n",
    "}\n",
    "def extract_json_between_markers(llm_output):\n",
    "    json_start_marker = \"{\"\n",
    "    json_end_marker = \"}\"\n",
    "\n",
    "    # Find the start and end indices of the JSON string\n",
    "    start_index = llm_output.find(json_start_marker)\n",
    "    if start_index != -1:\n",
    "        end_index = llm_output.find(json_end_marker, start_index)\n",
    "    else:\n",
    "        return schema  # JSON markers not found\n",
    "\n",
    "    if end_index == -1:\n",
    "        return schema  # End marker not found\n",
    "\n",
    "    # Extract the JSON string\n",
    "    json_string = llm_output[start_index:end_index+1].strip()\n",
    "    json_string = json_string.replace(\"'\", \"\\\"\")\n",
    "    try:\n",
    "        parsed_json = json.loads(json_string)\n",
    "        return parsed_json\n",
    "    except json.JSONDecodeError:\n",
    "        return schema  # Invalid JSON format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 清洗 json格式中键为 key 的数据， 数据集\n",
    "input_path_gpt = 'data/inference_data/gpt_shot.json'\n",
    "input_path_glm = 'data/inference_data/glm_shot.json'\n",
    "input_path_llama = 'data/inference_data/llama_shot.json'\n",
    "output_path = 'data/eval/eval.json'\n",
    "\n",
    "def filter_empty_json(json_list):\n",
    "    return {entity:value for entity,value in json_list.items() if len(value)}\n",
    "\n",
    "with open(input_path_gpt,'r',encoding='utf-8') as f:\n",
    "    gpt_data = json.load(f)\n",
    "\n",
    "with open(input_path_glm,'r',encoding='utf-8') as f:\n",
    "    glm_data = json.load(f)\n",
    "\n",
    "with open(input_path_llama,'r',encoding='utf-8') as f:\n",
    "    llama_data = json.load(f) \n",
    "\n",
    "final_data = [{} for i in range(len(glm_data))]\n",
    "for i in range(len(glm_data)):\n",
    "    # print(glm_data[i]['sentence'])\n",
    "    final_data[i]['sentence'] = glm_data[i]['sentence']\n",
    "    final_data[i]['target'] = filter_empty_json(gpt_data[i]['target'])\n",
    "    final_data[i]['gpt'] = filter_empty_json(extract_json_between_markers(gpt_data[i]['output']))\n",
    "    final_data[i]['glm'] = filter_empty_json(extract_json_between_markers(glm_data[i]['output']))\n",
    "    final_data[i]['llama'] = filter_empty_json(extract_json_between_markers(llama_data[i]['output']))\n",
    "\n",
    "with open(output_path, 'w', encoding='utf-8') as f:\n",
    "    json.dump(final_data, f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "# 清洗 json格式中键为 key 的数据， txt文件\n",
    "json_path = 'data/inference_data/final_res_part_1.jsonl'\n",
    "json_path2 = 'data/inference_data/final_res_part_2.jsonl'\n",
    "output_path = 'data/eval/final_res.json'\n",
    "\n",
    "# 过滤函数：过滤掉所有空的JSON对象\n",
    "def filter_empty_json(json_list):\n",
    "    return {entity:value for entity,value in json_list.items() if len(value)}\n",
    "\n",
    "with open(json_path, 'r', encoding='utf-8') as f:\n",
    "    data1 = [json.loads(line.strip()) for line in f]\n",
    "with open(json_path2, 'r', encoding='utf-8') as f:\n",
    "    data2 = [json.loads(line.strip()) for line in f]\n",
    "\n",
    "data = data1 + data2\n",
    "filtered_data = []\n",
    "for entry in data:\n",
    "    txt_path = entry.get('doi')\n",
    "    txt_output = entry.get('output', [])\n",
    "    filtered_txt_output = []\n",
    "    \n",
    "    for item in txt_output:\n",
    "        formatted_output = extract_json_between_markers(item['output'])\n",
    "        # print(formatted_output)\n",
    "        filtered_output = filter_empty_json(formatted_output)\n",
    "        \n",
    "        # 如果过滤后的output不是空列表，则保留该条目\n",
    "        if filtered_output:\n",
    "            filtered_txt_output.append(filtered_output)\n",
    "\n",
    "    temp = copy.deepcopy(schema)\n",
    "    for item in filtered_txt_output:\n",
    "        for entity,val in item.items():\n",
    "            if entity in temp:\n",
    "                temp[entity].extend(val)\n",
    "\n",
    "    filtered_data.append({'doi': txt_path, 'output': {k:list(set(v)) for k,v in temp.items()}})\n",
    "    \n",
    "with open(output_path, 'w', encoding='utf-8') as f:\n",
    "    json.dump(filtered_data, f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. TP,FP,FN 指标统计\n",
    "\n",
    "1. TP: target + , output +\n",
    "2. FP: target - , output +\n",
    "3. FN: target + , output -\n",
    "4. TN: target - , output -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"Seeded cell density\",'Number of cells','Channel height'\n",
    "\n",
    "entities = [\"Seeded cell density\",\n",
    "    \"Material in cell culture\", \"Concentration of material\", \"Chip material\", \n",
    "    \"Cross-linking agent\",\n",
    "    \"Pore size\", \"Diameter\", \"Manufacturing method\", \"Perfusion rate\", \n",
    "    \"Channel width\",'Channel height'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def convert_output(data):\n",
    "    \"\"\"\n",
    "    Convert the given data (target or output) into a set of key-value pairs\n",
    "    for comparison. Only include key-value pairs where the value is non-empty.\n",
    "    \"\"\"\n",
    "    res = set()\n",
    "    if not data:\n",
    "        return res\n",
    "    for key, value in data.items():\n",
    "        if value and key in entities:  # 只处理值非空的字段\n",
    "            for v in value:\n",
    "                res.add((key, v))  # 将每个(key, value)对加入到集合中\n",
    "    return res\n",
    "\n",
    "def calculate_f1_components(clean_target, clean_output):\n",
    "    \"\"\"\n",
    "    Calculate TP, FP, FN based on the target and output data.\n",
    "    \"\"\"\n",
    "    tp = []\n",
    "    fp = []\n",
    "    fn = []\n",
    "    \n",
    "        \n",
    "    # Convert target and output to sets of (key, value) pairs\n",
    "    target_set = convert_output(clean_target)\n",
    "    output_set = convert_output(clean_output)\n",
    "\n",
    "    # Calculate TP, FP, FN\n",
    "    tp_set = target_set.intersection(output_set)\n",
    "    fp_set = output_set.difference(target_set)\n",
    "    fn_set = target_set.difference(output_set)\n",
    "\n",
    "    # Store the results\n",
    "    tp.extend(tp_set)\n",
    "    fp.extend(fp_set)\n",
    "    fn.extend(fn_set)\n",
    "\n",
    "    return [k for k,v in tp], [k for k,v in fp], [k for k,v in fn]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 统计三个指标\n",
    "json_path = 'data/eval/eval.json'\n",
    "json_path = 'data/eval/sen_eval.json'\n",
    "with open(json_path,'r',encoding='utf-8') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "for item in data:\n",
    "    item['gpt_eval'],item['glm_eval'],item['llama_eval'] = {},{},{}\n",
    "    item['gpt_eval']['TP'], item['gpt_eval']['FP'], item['gpt_eval']['FN'] =  calculate_f1_components(item[\"target\"], item[\"gpt\"])\n",
    "    item['glm_eval']['TP'], item['glm_eval']['FP'], item['glm_eval']['FN'] =  calculate_f1_components(item[\"target\"], item[\"glm\"])\n",
    "    item['llama_eval']['TP'], item['llama_eval']['FP'], item['llama_eval']['FN'] =  calculate_f1_components(item[\"target\"], item[\"llama\"])\n",
    "with open(json_path, 'w', encoding='utf-8') as f:\n",
    "    json.dump(data, f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. 计算各实体的 F1 分数 \n",
    "\n",
    "由于之前的指标统计只是进行简单匹配，有的地方可能会判断失误，需进行人工校准。\n",
    "\n",
    "信息统计：结果存储在字典中，与excel统计一致：{entity1: [TP, FP, FN, TN, Accuracy, Precision, Recall, F1]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_f1(res,data,filed_name):\n",
    "    for item in data:\n",
    "        for entity in item[filed_name]['TP']:\n",
    "            res[entity][0] += 1\n",
    "        for entity in item[filed_name]['FP']:\n",
    "            res[entity][1] += 1\n",
    "        for entity in item[filed_name]['FN']:\n",
    "            res[entity][2] += 1\n",
    "        for entity in entities:\n",
    "            if entity not in item[filed_name]['TP'] and entity not in item[filed_name]['FP'] and entity not in item[filed_name]['FN']:\n",
    "                res[entity][3] += 1\n",
    "    for entity, counts in res.items():\n",
    "        TP, FP, FN, TN = counts[0], counts[1], counts[2], counts[3]\n",
    "        # Accuracy\n",
    "        res[entity][4] = round((TP + TN) / (TP + FP + FN + TN), 3) if (TP + FP + FN + TN) > 0 else -1\n",
    "        # Precision\n",
    "        res[entity][5] = round(TP / (TP + FP), 3) if (TP + FP) > 0 else -1\n",
    "        # Recall\n",
    "        res[entity][6] = round(TP / (TP + FN), 3) if (TP + FN) > 0 else -1\n",
    "        # F1-Score\n",
    "        res[entity][7] = round((2 * res[entity][5] * res[entity][6]) / (res[entity][5] + res[entity][6]), 3) if (res[entity][5] + res[entity][6]) > 0 else -1\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(json_path,'r',encoding='utf-8') as f:\n",
    "    data = json.load(f)\n",
    "# ['TP', 'FP', 'FN', 'TN', 'Accuracy', 'Precision', 'Recall', 'F1-Score']\n",
    "gpt_res = {entity: [0, 0, 0, 0, 0, 0, 0, 0] for entity in entities}\n",
    "glm_res = {entity: [0, 0, 0, 0, 0, 0, 0, 0] for entity in entities}\n",
    "llama_res = {entity: [0, 0, 0, 0, 0, 0, 0, 0] for entity in entities}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt_res = compute_f1(gpt_res,data,'gpt_eval')\n",
    "glm_res = compute_f1(glm_res,data,'glm_eval')\n",
    "llama_res = compute_f1(llama_res,data,'llama_eval')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Seeded cell density': [0.725, 0.675, 0.58],\n",
       " 'Material in cell culture': [0.887, 0.867, 0.705],\n",
       " 'Concentration of material': [0.811, 0.454, 0.39],\n",
       " 'Chip material': [0.909, 0.96, 0.891],\n",
       " 'Cross-linking agent': [0.95, 0.74, 0.687],\n",
       " 'Pore size': [0.75, 0.551, 0.692],\n",
       " 'Diameter': [0.906, 0.793, 0.745],\n",
       " 'Manufacturing method': [0.938, 0.656, 0.326],\n",
       " 'Perfusion rate': [0.844, 0.82, 0.731],\n",
       " 'Channel width': [0.909, 0.632, 0.5],\n",
       " 'Channel height': [0.903, 0.593, 0.815]}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_data = {}\n",
    "for entity in entities:\n",
    "    final_data[entity] = [gpt_res[entity][-1],glm_res[entity][-1],llama_res[entity][-1]]\n",
    "final_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----  llama  ----\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gpt</th>\n",
       "      <th>glm</th>\n",
       "      <th>llama</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Seeded cell density</th>\n",
       "      <td>0.725</td>\n",
       "      <td>0.675</td>\n",
       "      <td>0.580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Material in cell culture</th>\n",
       "      <td>0.887</td>\n",
       "      <td>0.867</td>\n",
       "      <td>0.705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Concentration of material</th>\n",
       "      <td>0.811</td>\n",
       "      <td>0.454</td>\n",
       "      <td>0.390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Chip material</th>\n",
       "      <td>0.909</td>\n",
       "      <td>0.960</td>\n",
       "      <td>0.891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cross-linking agent</th>\n",
       "      <td>0.950</td>\n",
       "      <td>0.740</td>\n",
       "      <td>0.687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pore size</th>\n",
       "      <td>0.750</td>\n",
       "      <td>0.551</td>\n",
       "      <td>0.692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Diameter</th>\n",
       "      <td>0.906</td>\n",
       "      <td>0.793</td>\n",
       "      <td>0.745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Manufacturing method</th>\n",
       "      <td>0.938</td>\n",
       "      <td>0.656</td>\n",
       "      <td>0.326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Perfusion rate</th>\n",
       "      <td>0.844</td>\n",
       "      <td>0.820</td>\n",
       "      <td>0.731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Channel width</th>\n",
       "      <td>0.909</td>\n",
       "      <td>0.632</td>\n",
       "      <td>0.500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Channel height</th>\n",
       "      <td>0.903</td>\n",
       "      <td>0.593</td>\n",
       "      <td>0.815</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             gpt    glm  llama\n",
       "Seeded cell density        0.725  0.675  0.580\n",
       "Material in cell culture   0.887  0.867  0.705\n",
       "Concentration of material  0.811  0.454  0.390\n",
       "Chip material              0.909  0.960  0.891\n",
       "Cross-linking agent        0.950  0.740  0.687\n",
       "Pore size                  0.750  0.551  0.692\n",
       "Diameter                   0.906  0.793  0.745\n",
       "Manufacturing method       0.938  0.656  0.326\n",
       "Perfusion rate             0.844  0.820  0.731\n",
       "Channel width              0.909  0.632  0.500\n",
       "Channel height             0.903  0.593  0.815"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "print('----  llama  ----')\n",
    "df = pd.DataFrame.from_dict(final_data, orient='index',columns=['gpt','glm','llama'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Seeded cell density': [28, 11, 16, 293, 0.922, 0.718, 0.636, 0.675],\n",
       " 'Material in cell culture': [147, 8, 37, 205, 0.887, 0.948, 0.799, 0.867],\n",
       " 'Concentration of material': [10, 1, 23, 308, 0.93, 0.909, 0.303, 0.454],\n",
       " 'Chip material': [48, 1, 3, 290, 0.988, 0.98, 0.941, 0.96],\n",
       " 'Cross-linking agent': [37, 0, 26, 288, 0.926, 1.0, 0.587, 0.74],\n",
       " 'Pore size': [8, 6, 7, 323, 0.962, 0.571, 0.533, 0.551],\n",
       " 'Diameter': [23, 3, 9, 309, 0.965, 0.885, 0.719, 0.793],\n",
       " 'Manufacturing method': [21, 2, 20, 298, 0.935, 0.913, 0.512, 0.656],\n",
       " 'Perfusion rate': [25, 4, 7, 308, 0.968, 0.862, 0.781, 0.82],\n",
       " 'Channel width': [12, 2, 12, 317, 0.959, 0.857, 0.5, 0.632],\n",
       " 'Channel height': [8, 4, 7, 323, 0.968, 0.667, 0.533, 0.593]}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glm_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Macro F1: 0.704\n",
      "Micro F1: 0.778\n"
     ]
    }
   ],
   "source": [
    "# 计算 Macro F1\n",
    "res =glm_res\n",
    "f1_scores = [counts[7] for counts in res.values() if counts[7] != -1]\n",
    "macro_f1 = round(sum(f1_scores) / len(f1_scores), 3) if f1_scores else -1\n",
    "\n",
    "# 计算 Micro F1\n",
    "total_tp = sum(counts[0] for counts in res.values())\n",
    "total_fp = sum(counts[1] for counts in res.values())\n",
    "total_fn = sum(counts[2] for counts in res.values())\n",
    "\n",
    "micro_precision = total_tp / (total_tp + total_fp) if (total_tp + total_fp) > 0 else -1\n",
    "micro_recall = total_tp / (total_tp + total_fn) if (total_tp + total_fn) > 0 else -1\n",
    "micro_f1 = round((2 * micro_precision * micro_recall) / (micro_precision + micro_recall), 3) if (micro_precision + micro_recall) > 0 else -1\n",
    "\n",
    "print(f\"Macro F1: {macro_f1}\")\n",
    "print(f\"Micro F1: {micro_f1}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llama",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
