### model
model_name_or_path: Model/Meta-Llama-3-8B-Instruct
template: llama3

### dataset
data_path: train.json
cutoff_len: 8192
preprocessing_num_workers: 16

### output
output_dir: llama3-8b/sft_193
logging_steps: 10
logging_first_step: true
save_steps: 500
overwrite_output_dir: true

### train
deepspeed_path: train/deepspeed_zero_stage2_config.json
per_device_train_batch_size: 2
gradient_accumulation_steps: 2
gradient_checkpointing: true
learning_rate: 2.0e-5
num_train_epochs: 1
lr_scheduler_type: WarmupLR
warmup_ratio: 0.05
lora_rank: 8
lora_dropout: 0.05
lora_alpha: 16
fp16: true
ddp_timeout: 180000000
swanlab:
  project: "llama3-fintune"
  experiment_name: "Llama-3-8B-Instruct"
  description: "使用Llama-3-8B-Instruct模型在肝器官数据集上微调，"
  config:
    model: "Llama-3-8B-Instruct"
    dataset: "liver_dataset"
